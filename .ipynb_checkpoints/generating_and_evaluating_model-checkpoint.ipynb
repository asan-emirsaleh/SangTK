{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# from bokeh.transform import jitter, factor_cmap\n",
    "# from bokeh.plotting import figure, output_notebook, show, ColumnDataSource\n",
    "# from bokeh.models import Legend, Range1d, LabelSet\n",
    "# from bokeh.io import export_png\n",
    "# from bokeh.palettes import brewer\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import scipy\n",
    "from scipy import stats\n",
    "\n",
    "import pickle\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, CuDNNLSTM, Bidirectional\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating dataframe to build nucleotide calling model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert abi files to dataframes for use:\n",
    "def abi_to_df(input_seqio_record):\n",
    "    # Getting the list of letters and their locations:\n",
    "    locations = list(input_seqio_record.annotations['abif_raw']['PLOC1'])\n",
    "    letters = list(input_seqio_record.annotations['abif_raw']['PBAS1'])\n",
    "    \n",
    "    # Converting to df:\n",
    "    letter_loc_df = pd.DataFrame()\n",
    "    letter_loc_df['Locations'] = locations\n",
    "    letter_loc_df['Letters'] = letters\n",
    "    \n",
    "    # Different df with all the waveform data:\n",
    "    peak_df = pd.DataFrame()\n",
    "    peak_df['g_let'] = list(input_seqio_record.annotations['abif_raw']['DATA9'])\n",
    "    peak_df['a_let'] = list(input_seqio_record.annotations['abif_raw']['DATA10'])\n",
    "    peak_df['t_let'] = list(input_seqio_record.annotations['abif_raw']['DATA11'])\n",
    "    peak_df['c_let'] = list(input_seqio_record.annotations['abif_raw']['DATA12'])\n",
    "    \n",
    "    # Making the indeces play nicely and deleting the other column:\n",
    "    peak_df['index_plus_one'] = peak_df.index + 1\n",
    "    peak_df.index = peak_df['index_plus_one']\n",
    "    letter_loc_df.index = letter_loc_df['Locations']\n",
    "    letter_loc_df.drop('Locations', inplace=True, axis=1)\n",
    "\n",
    "    # combining the dfs:\n",
    "    combined_df = letter_loc_df.join(peak_df, how='inner')\n",
    "    \n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example resulting dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Letters</th>\n",
       "      <th>g_let</th>\n",
       "      <th>a_let</th>\n",
       "      <th>t_let</th>\n",
       "      <th>c_let</th>\n",
       "      <th>index_plus_one</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>C</td>\n",
       "      <td>287</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>430</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>T</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>439</td>\n",
       "      <td>131</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>T</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>534</td>\n",
       "      <td>245</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>608</td>\n",
       "      <td>9</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>T</td>\n",
       "      <td>128</td>\n",
       "      <td>231</td>\n",
       "      <td>671</td>\n",
       "      <td>3</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>G</td>\n",
       "      <td>289</td>\n",
       "      <td>4</td>\n",
       "      <td>220</td>\n",
       "      <td>5</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>400</td>\n",
       "      <td>13</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>489</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>468</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>G</td>\n",
       "      <td>398</td>\n",
       "      <td>0</td>\n",
       "      <td>305</td>\n",
       "      <td>6</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Letters  g_let  a_let  t_let  c_let  index_plus_one\n",
       "41        C    287     34      0    430              41\n",
       "51        T     25      6    439    131              51\n",
       "61        T      5      0    534    245              61\n",
       "75        T      0     24    608      9              75\n",
       "86        T    128    231    671      3              86\n",
       "96        G    289      4    220      5              96\n",
       "106       T      1     11    400     13             106\n",
       "118       T      0     27    489      0             118\n",
       "130       T      0      6    468      0             130\n",
       "144       G    398      0    305      6             144"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in abi record:\n",
    "input_ab1 = SeqIO.read('./ab1_dir/gata2_31_200bpprom.custom2.ab1', 'abi')\n",
    "# Convert to dataframe:\n",
    "test_df = abi_to_df(input_ab1)\n",
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the file names\n",
    "mypath = './massive_training_set/ab1s/'\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "\n",
    "for idx, each_file in enumerate(onlyfiles):\n",
    "    current_record = SeqIO.read('./massive_training_set/ab1s/%s' % each_file, 'abi')\n",
    "    current_training_df = abi_to_df(current_record)\n",
    "    current_training_df['saving_og'] = current_training_df['Letters']\n",
    "    current_training_df.to_csv('./massive_training_set/nucleotide_dfs/%s.csv' % str(each_file.rsplit('.', 1)[0]), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating dataframe to build peak calling model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A few more required functions:\n",
    "\n",
    "# Adding the previous and the following base to the df:\n",
    "def surrounding_bases(input_df):\n",
    "    previous_letter_value_df = input_df.shift(1)\n",
    "    previous_letter_value_df.dropna(inplace=True)\n",
    "    previous_letter_value_df.rename({'a_let':'prev_a','c_let':'prev_c','t_let':'prev_t','g_let':'prev_g'}, inplace=True, axis=1)\n",
    "\n",
    "    following_letter_value_df = input_df.shift(-1)\n",
    "    following_letter_value_df.dropna(inplace=True)\n",
    "    following_letter_value_df.rename({'a_let':'next_a','c_let':'next_c','t_let':'next_t','g_let':'next_g'}, inplace=True, axis=1)\n",
    "\n",
    "    current_previous_following_df = pd.concat([input_df, previous_letter_value_df, following_letter_value_df], axis=1, join='inner')\n",
    "    return current_previous_following_df\n",
    "\n",
    "# Just reading in all the waverform data\n",
    "def for_peak_prediction(input_seqio_record):\n",
    "    # Different df with all the waveform data:\n",
    "    peak_val = pd.DataFrame()\n",
    "    peak_val['g_let'] = list(input_seqio_record.annotations['abif_raw']['DATA9'])\n",
    "    peak_val['a_let'] = list(input_seqio_record.annotations['abif_raw']['DATA10'])\n",
    "    peak_val['t_let'] = list(input_seqio_record.annotations['abif_raw']['DATA11'])\n",
    "    peak_val['c_let'] = list(input_seqio_record.annotations['abif_raw']['DATA12'])\n",
    "        \n",
    "    return peak_val\n",
    "\n",
    "# This combines a peak df with a full record\n",
    "def peak_calling_df(input_df, input_seqio_record):\n",
    "    input_df['peak_no_peak'] = [1] * input_df.shape[0]\n",
    "    input_df.index = input_df.index + 1####MAYBE KEEP THIS IN? MAYBE REMOVE IT?\n",
    "    first_val = input_df.index[0] - 5\n",
    "    last_val = input_df.index[-1] + 5\n",
    "    removed_df = input_df[['peak_no_peak']]\n",
    "    # Different df with all the waveform data:\n",
    "    peak_val = pd.DataFrame()\n",
    "    peak_val['g_let'] = list(input_seqio_record.annotations['abif_raw']['DATA9'])\n",
    "    peak_val['a_let'] = list(input_seqio_record.annotations['abif_raw']['DATA10'])\n",
    "    peak_val['t_let'] = list(input_seqio_record.annotations['abif_raw']['DATA11'])\n",
    "    peak_val['c_let'] = list(input_seqio_record.annotations['abif_raw']['DATA12'])\n",
    "    \n",
    "    peak_val = peak_val.loc[first_val:last_val]\n",
    "    fin_df = removed_df.merge(peak_val, how='outer', left_index=True, right_index=True)\n",
    "    zero = fin_df[fin_df['peak_no_peak'] !=1]\n",
    "    zero['peak_no_peak'] = [0] * zero.shape[0]\n",
    "    nonzero = fin_df[fin_df['peak_no_peak'] ==1]\n",
    "    fin_df = zero.append(nonzero)\n",
    "    fin_df.sort_index(inplace=True)\n",
    "\n",
    "    return fin_df\n",
    "\n",
    "def slope(inp_df):\n",
    "    only_letters = inp_df[['g_let', 'a_let', 't_let', 'c_let']]\n",
    "    slope_before = only_letters.diff(1, axis=0)\n",
    "    slope_before.columns = ['slope_g_after', 'slope_a_after', 'slope_t_after', 'slope_c_after']\n",
    "    slope_after = only_letters.diff(-1, axis=0)\n",
    "    slope_after.columns = ['slope_g_before', 'slope_a_before', 'slope_t_before', 'slope_c_before']\n",
    "    \n",
    "    final = only_letters.join(slope_before)\n",
    "    final = final.join(slope_after)\n",
    "    final = final.join(inp_df[['peak_no_peak']])\n",
    "    \n",
    "    return final\n",
    "\n",
    "def normalizing(inp_df):\n",
    "    all_peak_places = inp_df[inp_df['peak_no_peak'] == 1]\n",
    "    all_peak_places_vals = all_peak_places[['g_let', 'a_let', 't_let', 'c_let']]\n",
    "    all_max_peaks = list(all_peak_places_vals.max(axis=1))\n",
    "    trimmed_mean = scipy.stats.trim_mean(all_max_peaks, proportiontocut=0.1)\n",
    "    inp_df = inp_df / trimmed_mean\n",
    "    inp_df['peak_no_peak'] = inp_df['peak_no_peak'] * trimmed_mean\n",
    "    inp_df['peak_no_peak'] = inp_df['peak_no_peak'].astype(int)\n",
    "    return inp_df\n",
    "\n",
    "def finding_taller_peak(the_input_df):\n",
    "    # Getting all of the peaks:\n",
    "    peaks = the_input_df[the_input_df['peak_no_peak'] == 1]\n",
    "    # Getting the indeces of all of the peaks:\n",
    "    peak_indeces = list(peaks.index)\n",
    "    # Getting the surrounding four rows:\n",
    "    before_peaks = [item - 4 for item in peak_indeces]\n",
    "    after_peaks = [item + 4 for item in peak_indeces]\n",
    "    # Going through each peak and respective rows:\n",
    "    for idx, item in enumerate(before_peaks):\n",
    "        # Making the smaller df:\n",
    "        temp_df = the_input_df.loc[item:after_peaks[idx]]\n",
    "        current_peak_loc = temp_df[temp_df['peak_no_peak'] == 1].index.tolist()[0]\n",
    "        just_letts = temp_df[['g_let','a_let','t_let','c_let']]\n",
    "        # Getting the max value of the dataframe:\n",
    "        max_val = max(just_letts.max(axis=1))\n",
    "        # Getting the index of the max value:\n",
    "        max_idx = int(temp_df[temp_df.values == max_val].index.tolist()[0])\n",
    "        max_letter = just_letts.loc[max_idx].idxmax(axis=1)\n",
    "\n",
    "        # Acquiring the slopes:\n",
    "        before_slopes = pd.DataFrame(temp_df.loc[max_idx][['slope_g_before','slope_a_before','slope_t_before','slope_c_before']]).T\n",
    "        before_slopes.columns = ['g_let','a_let','t_let','c_let']\n",
    "        after_slopes = pd.DataFrame(temp_df.loc[max_idx][['slope_g_after','slope_g_after','slope_g_after','slope_g_after']]).T\n",
    "        after_slopes.columns = ['g_let','a_let','t_let','c_let']\n",
    "\n",
    "        # If they're both positive:\n",
    "        val_1 = before_slopes[[max_letter]].values >= 0\n",
    "        val_1 = val_1[0][0]\n",
    "        val_2 = after_slopes[[max_letter]].values >= 0\n",
    "        val_2 = val_2[0][0]\n",
    "        if val_1 and val_2:\n",
    "            the_input_df['peak_no_peak'][current_peak_loc] = 0\n",
    "            the_input_df['peak_no_peak'][max_idx] = 1     \n",
    "\n",
    "    return the_input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandredaly/anaconda/envs/python3/lib/python3.5/site-packages/ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peak_no_peak</th>\n",
       "      <th>g_let</th>\n",
       "      <th>a_let</th>\n",
       "      <th>t_let</th>\n",
       "      <th>c_let</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.0</td>\n",
       "      <td>432</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.0</td>\n",
       "      <td>382</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.0</td>\n",
       "      <td>333</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.0</td>\n",
       "      <td>287</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.0</td>\n",
       "      <td>244</td>\n",
       "      <td>34</td>\n",
       "      <td>18</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.0</td>\n",
       "      <td>205</td>\n",
       "      <td>36</td>\n",
       "      <td>49</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.0</td>\n",
       "      <td>170</td>\n",
       "      <td>38</td>\n",
       "      <td>92</td>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.0</td>\n",
       "      <td>136</td>\n",
       "      <td>39</td>\n",
       "      <td>142</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.0</td>\n",
       "      <td>105</td>\n",
       "      <td>38</td>\n",
       "      <td>202</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.0</td>\n",
       "      <td>79</td>\n",
       "      <td>33</td>\n",
       "      <td>256</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    peak_no_peak  g_let  a_let  t_let  c_let\n",
       "37           0.0    432     46      0    396\n",
       "38           0.0    382     40      0    418\n",
       "39           0.0    333     36      0    429\n",
       "40           0.0    287     34      0    430\n",
       "41           0.0    244     34     18    419\n",
       "42           1.0    205     36     49    398\n",
       "43           0.0    170     38     92    367\n",
       "44           0.0    136     39    142    331\n",
       "45           0.0    105     38    202    291\n",
       "46           0.0     79     33    256    250"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading in the ab1 file\n",
    "sequence_record = SeqIO.read('./ab1_dir/gata2_31_200bpprom.custom2.ab1', 'abi')\n",
    "\n",
    "# Generating the nucleotide dataframe, which will be important for nucleotide calling:\n",
    "nucleotide_df = abi_to_df(sequence_record)\n",
    "\n",
    "# To generate the dataframe of the peaks, we also use the nucleotide dataframe generated above:\n",
    "nucleotide_df.set_index('index_plus_one', inplace=True)\n",
    "\n",
    "# Generating the peak_df using the nucleotide dataframe:\n",
    "peak_df = peak_calling_df(nucleotide_df, sequence_record)\n",
    "\n",
    "# Example of the dataframe\n",
    "peak_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning up the dataframe a little bit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the value:\n",
    "peak_df = normalizing(peak_df)\n",
    "\n",
    "# A helpful feature is finding the slope before and after each location:\n",
    "peak_df = slope(peak_df)\n",
    "\n",
    "# It turns out that the peaks called in the ab1 file are often not the peaks - fixing this:\n",
    "finding_taller_peak(peak_df)\n",
    "\n",
    "# Writing the files to a csv:\n",
    "finding_taller_peak.to_csv('./data/peak_files/peak_file_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### A quick aside: showing the reason peaks need to be 'fixed':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vals_before_or_after(inp_df, val_to_check, return_peak_val=False):\n",
    "    # Getting the peak values\n",
    "    peaks = inp_df[inp_df['peak_no_peak'] == 1]\n",
    "    peak_locs = list(peaks.index)\n",
    "    just_letter_peaks = peaks[['g_let', 'a_let', 't_let', 'c_let']]\n",
    "    peak_max_val = list(just_letter_peaks.max(axis=1))\n",
    "\n",
    "    # Getting the values one before peak:\n",
    "    one_bef_peak = [item + val_to_check for item in peak_locs]\n",
    "    one_bef_df = inp_df.loc[one_bef_peak]\n",
    "    just_letter_one_bef = one_bef_df[['g_let', 'a_let', 't_let', 'c_let']]\n",
    "    one_bef_max_val = list(just_letter_one_bef.max(axis=1))\n",
    "    \n",
    "    if return_peak_val == True:\n",
    "        return peak_max_val, one_bef_max_val\n",
    "    else:\n",
    "        return one_bef_max_val\n",
    "    \n",
    "def remove_nans(input_list):\n",
    "    input_list = np.array(input_list)\n",
    "    final_list = input_list[~np.isnan(input_list)]\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in both fixed and unfixed peaks:\n",
    "unfixed_path = './data/unfixed_peaks/'\n",
    "fixed_path = './data/fixed_peaks/'\n",
    "\n",
    "# The filenames are all the same:\n",
    "filenames = [f for f in listdir(unfixed_path) if isfile(join(unfixed_path, f))]\n",
    "\n",
    "fixed_df = pd.DataFrame()\n",
    "unfixed_df = pd.DataFrame()\n",
    "for idx, item in enumerate(filenames):\n",
    "    \n",
    "    # Opening the peak files:\n",
    "    temp_fixed = pd.read_csv('%s%s' % (fixed_path, item), index_col=0)\n",
    "    temp_unfixed = pd.read_csv('%s%s' % (unfixed_path, item), index_col=0)\n",
    "    \n",
    "    # I'm only training data on the files that have > 1000 peaks, so staying consistent:\n",
    "    peaks = temp_fixed[temp_fixed['peak_no_peak'] == 1].shape[0] \n",
    "    \n",
    "    if peaks < 1000:\n",
    "        continue\n",
    "    \n",
    "    # Getting the data:\n",
    "    fixed_df = fixed_df.append(temp_fixed)\n",
    "    unfixed_df = unfixed_df.append(temp_unfixed)\n",
    "    \n",
    "    # Reindexing:\n",
    "    fixed_df.reset_index(inplace=True, drop=True)\n",
    "    unfixed_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One before:\n",
    "one_bef_max_val_fixed = vals_before_or_after(fixed_df, -1)\n",
    "one_bef_max_val_fixed = remove_nans(one_bef_max_val_fixed)\n",
    "# Two before:\n",
    "two_bef_max_val_fixed = vals_before_or_after(fixed_df, -2)\n",
    "two_bef_max_val_fixed = remove_nans(two_bef_max_val_fixed)\n",
    "\n",
    "# One after:\n",
    "one_aft_max_val_fixed = vals_before_or_after(fixed_df, 1)\n",
    "one_aft_max_val_fixed = remove_nans(one_aft_max_val_fixed)\n",
    "# Two after:\n",
    "peak_list_fixed, two_aft_max_val_fixed = vals_before_or_after(fixed_df, 2, return_peak_val=True)\n",
    "two_aft_max_val_fixed = remove_nans(two_aft_max_val_fixed)\n",
    "\n",
    "peak_list_fixed = remove_nans(peak_list_fixed)\n",
    "\n",
    "# One before:\n",
    "one_bef_max_val_unfixed = vals_before_or_after(unfixed_df, -1)\n",
    "one_bef_max_val_unfixed = remove_nans(one_bef_max_val_unfixed)\n",
    "# Two before:\n",
    "two_bef_max_val_unfixed = vals_before_or_after(unfixed_df, -2)\n",
    "two_bef_max_val_unfixed = remove_nans(two_bef_max_val_unfixed)\n",
    "\n",
    "# One after:\n",
    "one_aft_max_val_unfixed = vals_before_or_after(unfixed_df, 1)\n",
    "one_aft_max_val_unfixed = remove_nans(one_aft_max_val_unfixed)\n",
    "# Two after:\n",
    "peak_list_unfixed, two_aft_max_val_unfixed = vals_before_or_after(unfixed_df, 2, return_peak_val=True)\n",
    "two_aft_max_val_unfixed = remove_nans(two_aft_max_val_unfixed)\n",
    "\n",
    "peak_list_unfixed = remove_nans(peak_list_unfixed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the peaks are truly peaks, it would make sense for the peak values to be learger than the values around the peaks (the values one or two away from the peaks). Above I've collected the values for the peak, and also values around the peaks. Below shows some basic statistics concerning these values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is **no** statistically significant difference in value between peaks and the location immediately preceding the unfixed dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=-0.040668072386749146, pvalue=0.9675605954457309)\n",
      "Ttest_indResult(statistic=21.544653589484465, pvalue=1.0135537630178583e-102)\n",
      "Ttest_indResult(statistic=21.678101431726425, pvalue=5.707574598217427e-104)\n",
      "Ttest_indResult(statistic=64.04771978175397, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "print(stats.ttest_ind(peak_list_unfixed, one_bef_max_val_unfixed))\n",
    "print(stats.ttest_ind(peak_list_unfixed, two_bef_max_val_unfixed))\n",
    "print(stats.ttest_ind(peak_list_unfixed, one_aft_max_val_unfixed))\n",
    "print(stats.ttest_ind(peak_list_unfixed, two_aft_max_val_unfixed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But there **is** a statistically significant difference between the peak and the preceding location in the fixed dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=9.863928286164338, pvalue=6.111105860165287e-23)\n",
      "Ttest_indResult(statistic=41.321722638055824, pvalue=0.0)\n",
      "Ttest_indResult(statistic=11.75841375265852, pvalue=6.706368985940247e-32)\n",
      "Ttest_indResult(statistic=44.70384963811799, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "print(stats.ttest_ind(peak_list_fixed, one_bef_max_val_fixed))\n",
    "print(stats.ttest_ind(peak_list_fixed, two_bef_max_val_fixed))\n",
    "print(stats.ttest_ind(peak_list_fixed, one_aft_max_val_fixed))\n",
    "print(stats.ttest_ind(peak_list_fixed, two_aft_max_val_fixed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the means for both datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0324283429362433\n",
      "1.0325583225972772\n",
      "0.9665951758173349\n",
      "0.9659391438930929\n",
      "0.8488926566523692\n",
      "\n",
      "\n",
      "\n",
      "1.0490920627668103\n",
      "1.0180408552804372\n",
      "0.9263168518897866\n",
      "1.0121686505409637\n",
      "0.916809043693293\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(peak_list_unfixed))\n",
    "print(np.mean(one_bef_max_val_unfixed))\n",
    "print(np.mean(two_bef_max_val_unfixed))\n",
    "print(np.mean(one_aft_max_val_unfixed))\n",
    "print(np.mean(two_aft_max_val_unfixed))\n",
    "print('\\n\\n')\n",
    "print(np.mean(peak_list_fixed))\n",
    "print(np.mean(one_bef_max_val_fixed))\n",
    "print(np.mean(two_bef_max_val_fixed))\n",
    "print(np.mean(one_aft_max_val_fixed))\n",
    "print(np.mean(two_aft_max_val_fixed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly the mean of the fixed set is quite significant. The difference in distributions can be seen by plotting the values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfixed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.hist(peak_list_unfixed, alpha=0.3, color='red', bins=50, range=[0,5])\n",
    "_ = plt.hist(one_bef_max_val_unfixed, alpha=0.3, color='blue', bins=50, range=[0,5])\n",
    "_ = plt.hist(two_bef_max_val_unfixed, alpha=0.3, color='green', bins=50, range=[0,5])\n",
    "_ = plt.hist(one_aft_max_val_unfixed, alpha=0.3, color='yellow', bins=50, range=[0,5])\n",
    "_ = plt.hist(two_aft_max_val_unfixed, alpha=0.3, color='black', bins=50, range=[0,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.hist(peak_list_fixed, alpha=0.3, color='red', bins=50, range=[0,5])\n",
    "_ = plt.hist(one_bef_max_val_fixed, alpha=0.3, color='blue', bins=50, range=[0,5])\n",
    "_ = plt.hist(two_bef_max_val_fixed, alpha=0.3, color='green', bins=50, range=[0,5])\n",
    "_ = plt.hist(one_aft_max_val_fixed, alpha=0.3, color='yellow', bins=50, range=[0,5])\n",
    "_ = plt.hist(two_aft_max_val_fixed, alpha=0.3, color='black', bins=50, range=[0,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building and running nucleotide calling function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the data:\n",
    "mypath = './data/nucleotide_dfs/'\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "training_df = pd.DataFrame()\n",
    "for item in onlyfiles:\n",
    "    temp_training = pd.read_csv('%s%s' % (mypath, item))\n",
    "    training_df = training_df.append(temp_training)\n",
    "\n",
    "training_df.reset_index(inplace=True)\n",
    "\n",
    "# Setting up the df columns:\n",
    "letter_value_df = training_df[['a_let', 'c_let', 't_let', 'g_let']]\n",
    "called_letter_df = training_df[['Letters']]\n",
    "\n",
    "# Getting the info from previous and next base:\n",
    "full_info_df = surrounding_bases(letter_value_df)\n",
    "full_info_df = full_info_df.values.tolist()\n",
    "\n",
    "# Dropping the first and last letters since their values get clipped\n",
    "called_letter_df = called_letter_df[1:]\n",
    "called_letter_df.drop(called_letter_df.tail(1).index,inplace=True)\n",
    "called_letter_list = list(called_letter_df['Letters'])\n",
    "called_letter_array = [[item] for item in called_letter_list]\n",
    "\n",
    "# Running the model:\n",
    "full_log_reg = linear_model.LogisticRegression(C=1,penalty='l2',solver='liblinear',tol=0.0001)\n",
    "\n",
    "# Saving the model:\n",
    "# pickle.dump(full_log_reg, open('log_reg_default_million.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building and running peak calling function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshaping_the_df(inp_df, first_dim, second_dim, third_dim):\n",
    "    y_val_train = np.array(inp_df['peak_no_peak'])\n",
    "    inp_df = inp_df.iloc[:,:-1]\n",
    "    x_val_train = inp_df.values.reshape((first_dim,second_dim,third_dim))\n",
    "    return x_val_train, y_val_train    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the training df larger:\n",
    "mypath = './data/fixed_peaks/'\n",
    "df_files = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "\n",
    "for idx, item in enumerate(df_files):\n",
    "    \n",
    "    # Opening the peak file\n",
    "    temp_training = pd.read_csv('%s%s' % (mypath, item), index_col=0)\n",
    "    \n",
    "    # Counting how many peaks there are:\n",
    "    how_many_peaks = temp_training[temp_training['peak_no_peak']==1].shape[0]\n",
    "    \n",
    "    # Drop the files that have fewer than 1000 peaks\n",
    "    if how_many_peaks < 1000:\n",
    "        continue\n",
    "        \n",
    "    # OPTIONAL - dropping the files that have fewer than 120000 peaks\n",
    "    if temp_training.shape[0] < 12000:\n",
    "        continue\n",
    "        \n",
    "    # Removing na rows (there's at least two in each df)\n",
    "    temp_training.dropna(inplace=True)\n",
    "\n",
    "    if idx == 0:\n",
    "        final_df = temp_training\n",
    "        \n",
    "    else:\n",
    "        final_df = final_df.append(temp_training)        \n",
    "        \n",
    "# Train-test splitting:\n",
    "split_val = math.floor(float(final_df.shape[0]) * 0.8)\n",
    "training_df = final_df[:split_val]\n",
    "test_df = final_df[split_val:]\n",
    "\n",
    "# \n",
    "training_array_x, training_array_y = reshaping_the_df(training_df, training_df.shape[0], 1, 12)\n",
    "testing_array_x, testing_array_y = reshaping_the_df(test_df, test_df.shape[0], 1, 12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
